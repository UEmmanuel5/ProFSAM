{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78621ab3",
   "metadata": {},
   "source": [
    "## YOLOv11 + SAM2 Video Segmentation with Grid Sampling & HSV Filtering\n",
    "Processes video frames with YOLOv11 for detection and SAM2 for segmentation using multiple grid-sampled points filtered by HSV fire-color heuristic.  \n",
    "Saves:\n",
    "- detection frames  \n",
    "- masks  \n",
    "- overlays  \n",
    "- grid points before/after filtering  \n",
    "Outputs final annotated video and reports model size, FPS, inference time, and GPU memory usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699b1de",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "\n",
    "VIDEO_PATH   = \"\"   # Directory containing input video\n",
    "YOLO_MODEL   = \"\"   # Path to YOLO model weights\n",
    "SAM2_CFG     = \"\"   # Path to SAM2 base_plus config\n",
    "SAM2_WEIGHTS = \"\"   # Path to SAM2 base_plus weights\n",
    "OUT_DIR      = \"\"   # Output directory for results\n",
    "IMG_SIZE     = 960\n",
    "CONF_THRESH  = 0.3\n",
    "GRID_SIZE    = 3   # number of grid points 3x3\n",
    "DEVICE       = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "mask_dir = os.path.join(OUT_DIR, 'masks')\n",
    "overlay_dir = os.path.join(OUT_DIR, 'overlays')\n",
    "det_dir = os.path.join(OUT_DIR, 'detected_fires')\n",
    "prompt_before_dir = os.path.join(OUT_DIR, 'prompts_before_filter')\n",
    "prompt_after_dir = os.path.join(OUT_DIR, 'prompts_after_filter')\n",
    "os.makedirs(mask_dir, exist_ok=True)\n",
    "os.makedirs(overlay_dir, exist_ok=True)\n",
    "os.makedirs(det_dir, exist_ok=True)\n",
    "os.makedirs(prompt_before_dir, exist_ok=True)\n",
    "os.makedirs(prompt_after_dir, exist_ok=True)\n",
    "\n",
    "yolo_model = YOLO(YOLO_MODEL).to(DEVICE)\n",
    "def load_sam(cfg, ckpt, device):\n",
    "    model = build_sam2(cfg, ckpt, device=device)\n",
    "    return SAM2ImagePredictor(model)\n",
    "sam_predictor = load_sam(SAM2_CFG, SAM2_WEIGHTS, DEVICE)\n",
    "\n",
    "def grid_points_from_box(x1, y1, x2, y2, grid_size):\n",
    "    xs = np.linspace(x1, x2, grid_size+2, dtype=int)[1:-1]\n",
    "    ys = np.linspace(y1, y2, grid_size+2, dtype=int)[1:-1]\n",
    "    return [[int(x), int(y)] for x in xs for y in ys]\n",
    "\n",
    "def is_fire_pixel(h, s, v):\n",
    "    return (0 <= h <= 60) and (s >= 100) and (v >= 150)\n",
    "\n",
    "def filter_fire_points(img, points):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    fire_points = []\n",
    "    for (x, y) in points:\n",
    "        if x < 0 or y < 0 or x >= img.shape[1] or y >= img.shape[0]:\n",
    "            continue\n",
    "        h, s, v = hsv[y, x]\n",
    "        if is_fire_pixel(h, s, v):\n",
    "            fire_points.append([x, y])\n",
    "    if len(fire_points) == 0:\n",
    "        cx = int(np.mean([p[0] for p in points]))\n",
    "        cy = int(np.mean([p[1] for p in points]))\n",
    "        fire_points.append([cx, cy])\n",
    "    return fire_points\n",
    "\n",
    "def visualize_points(img, points, path, color=(0,255,0)):\n",
    "    vis = img.copy()\n",
    "    for (x, y) in points:\n",
    "        cv2.circle(vis, (x, y), 4, color, -1)\n",
    "    cv2.imwrite(path, cv2.cvtColor(vis, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "param_count_yolo = sum(p.numel() for p in yolo_model.model.parameters())\n",
    "param_count_sam2 = sum(p.numel() for p in sam_predictor.model.parameters())\n",
    "model_size_mb = (param_count_yolo + param_count_sam2) * 4 / (1024**2)\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "print(f\"YOLO Parameters: {param_count_yolo:,}\")\n",
    "print(f\"SAM2 Parameters: {param_count_sam2:,}\")\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out_video_path = os.path.join(OUT_DIR, \"final_output.avi\")\n",
    "out_writer = cv2.VideoWriter(out_video_path, fourcc, fps, (frame_w, frame_h))\n",
    "\n",
    "frame_count = 0\n",
    "total_time = 0.0\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(img_rgb)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    results = yolo_model.predict([img_pil], imgsz=IMG_SIZE, conf=CONF_THRESH, verbose=False)\n",
    "    boxes_xyxy = results[0].boxes.xyxy.cpu().numpy()\n",
    "    confs = results[0].boxes.conf.cpu().numpy()\n",
    "\n",
    "    det_vis = img_rgb.copy()\n",
    "    for box, conf in zip(boxes_xyxy, confs):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cv2.rectangle(det_vis, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(det_vis, f\"{conf:.2f}\", (x1 - 50, y1 + 15),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    cv2.imwrite(os.path.join(det_dir, f\"{frame_count:05d}.png\"),\n",
    "                cv2.cvtColor(det_vis, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    sam_predictor.set_image(img_rgb)\n",
    "    final_mask = np.zeros(img_rgb.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    for box in boxes_xyxy:\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        grid_points = grid_points_from_box(x1, y1, x2, y2, GRID_SIZE)\n",
    "        visualize_points(img_rgb, grid_points,\n",
    "                         os.path.join(prompt_before_dir, f\"{frame_count:05d}.png\"),\n",
    "                         color=(0,0,255))\n",
    "        filtered_points = filter_fire_points(img_rgb, grid_points)\n",
    "        visualize_points(img_rgb, filtered_points,\n",
    "                         os.path.join(prompt_after_dir, f\"{frame_count:05d}.png\"),\n",
    "                         color=(0,255,0))\n",
    "        point_coords = np.array(filtered_points)\n",
    "        point_labels = np.ones(len(filtered_points))\n",
    "        masks, scores, _ = sam_predictor.predict(\n",
    "            point_coords=point_coords,\n",
    "            point_labels=point_labels,\n",
    "            box=box[None, :],\n",
    "            multimask_output=False,\n",
    "        )\n",
    "        mask = masks[0].astype(np.uint8)\n",
    "        final_mask = np.maximum(final_mask, mask)\n",
    "\n",
    "    cv2.imwrite(os.path.join(mask_dir, f\"{frame_count:05d}.png\"), final_mask * 255)\n",
    "    overlay = img_rgb.copy()\n",
    "    red = np.zeros_like(img_rgb); red[:] = (255, 0, 0)\n",
    "    alpha = 0.4\n",
    "    overlay = np.where(final_mask[..., None] == 1,\n",
    "                       cv2.addWeighted(overlay, 1 - alpha, red, alpha, 0),\n",
    "                       overlay)\n",
    "    overlay_bgr = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(os.path.join(overlay_dir, f\"{frame_count:05d}.png\"), overlay_bgr)\n",
    "\n",
    "    out_writer.write(overlay_bgr)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    total_time += elapsed\n",
    "    print(f\"[{frame_count}] Frame processed in {elapsed*1000:.2f} ms\")\n",
    "\n",
    "cap.release()\n",
    "out_writer.release()\n",
    "\n",
    "avg_time_ms = (total_time / frame_count) * 1000\n",
    "fps_actual = frame_count / total_time\n",
    "peak_mem_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "\n",
    "print(f\"\\n--- Computational Efficiency ---\")\n",
    "print(f\"Average Inference Time: {avg_time_ms:.2f} ms/frame\")\n",
    "print(f\"FPS: {fps_actual:.2f}\")\n",
    "print(f\"Peak GPU Memory: {peak_mem_mb:.2f} MB\")\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "print(f\"Output video saved to: {out_video_path}\")\n",
    "print(f\"All detection images, masks, overlays, and prompt visualizations saved to: {OUT_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
