{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa57536",
   "metadata": {},
   "source": [
    "## YOLOv11 â†’ SAM2 pipeline for fire segmentation (Box + SP)\n",
    "Prompts SAM2 with both the bounding box and a single positive point at its centroid.  \n",
    "Saves:\n",
    "- detection images\n",
    "- prompt visualizations\n",
    "- masks\n",
    "- overlays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97a048",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "FRAME_DIR    = \"\"   # Directory containing input frames\n",
    "YOLO_MODEL   = \"\"   # Path to YOLO model weights\n",
    "SAM2_CFG     = \"\"   # Path to SAM2 config\n",
    "SAM2_WEIGHTS = \"\"   # Path to SAM2 weights\n",
    "OUT_DIR      = \"\"   # Output directory for results\n",
    "IMG_SIZE     = 960\n",
    "CONF_THRESH  = 0.3\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "yolo_model = YOLO(YOLO_MODEL).to(DEVICE)\n",
    "\n",
    "def load_sam(cfg, ckpt, device):\n",
    "    model = build_sam2(cfg, ckpt, device=device)\n",
    "    return SAM2ImagePredictor(model)\n",
    "\n",
    "sam_predictor = load_sam(SAM2_CFG, SAM2_WEIGHTS, DEVICE)\n",
    "\n",
    "mask_dir = os.path.join(OUT_DIR, 'masks')\n",
    "overlay_dir = os.path.join(OUT_DIR, 'overlays')\n",
    "det_dir = os.path.join(OUT_DIR, 'detected_fires')\n",
    "prompt_dir = os.path.join(OUT_DIR, 'prompts_box_sp')\n",
    "os.makedirs(mask_dir, exist_ok=True)\n",
    "os.makedirs(overlay_dir, exist_ok=True)\n",
    "os.makedirs(det_dir, exist_ok=True)\n",
    "os.makedirs(prompt_dir, exist_ok=True)\n",
    "\n",
    "frame_paths = sorted(\n",
    "    sum([glob.glob(os.path.join(FRAME_DIR, ext)) for ext in (\"*.jpg\", \"*.png\")], [])\n",
    ")\n",
    "\n",
    "for idx, path in enumerate(frame_paths):\n",
    "    img_pil = Image.open(path).convert('RGB')\n",
    "    img_np  = np.array(img_pil)\n",
    "\n",
    "    results = yolo_model.predict([img_pil], imgsz=IMG_SIZE, conf=CONF_THRESH)\n",
    "    boxes_xyxy = results[0].boxes.xyxy.cpu().numpy()\n",
    "    confs = results[0].boxes.conf.cpu().numpy()\n",
    "\n",
    "    det_vis = img_np.copy()\n",
    "    for box, conf in zip(boxes_xyxy, confs):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cv2.rectangle(det_vis, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        cv2.putText(det_vis, f\"{conf:.2f}\", (x1 - 50, y1 + 15),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    cv2.imwrite(os.path.join(det_dir, f\"{idx:05d}.png\"),\n",
    "                cv2.cvtColor(det_vis, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    sam_predictor.set_image(img_np)\n",
    "    final_mask = np.zeros(img_np.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    prompt_vis = img_np.copy()\n",
    "\n",
    "    for box, conf in zip(boxes_xyxy, confs):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cx, cy = int((x1+x2)/2), int((y1+y2)/2)\n",
    "\n",
    "        cv2.rectangle(prompt_vis, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.circle(prompt_vis, (cx, cy), 5, (0, 0, 255), -1)\n",
    "        cv2.putText(prompt_vis, f\"{conf:.2f}\", (x1 - 50, y1 + 15),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        point_coords = np.array([[cx, cy]])\n",
    "        point_labels = np.array([1])\n",
    "\n",
    "        masks, scores, _ = sam_predictor.predict(\n",
    "            point_coords=point_coords,\n",
    "            point_labels=point_labels,\n",
    "            box=np.array([x1, y1, x2, y2])[None, :],\n",
    "            multimask_output=False,\n",
    "        )\n",
    "        mask = masks[0].astype(np.uint8)\n",
    "        final_mask = np.maximum(final_mask, mask)\n",
    "\n",
    "    cv2.imwrite(os.path.join(prompt_dir, f\"{idx:05d}.png\"),\n",
    "                cv2.cvtColor(prompt_vis, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    mask_filename = f\"{idx:05d}.png\"\n",
    "    cv2.imwrite(os.path.join(mask_dir, mask_filename), final_mask * 255)\n",
    "\n",
    "    overlay = img_np.copy()\n",
    "    red = np.zeros_like(img_np); red[:] = (255, 0, 0)\n",
    "    alpha = 0.4\n",
    "    overlay = np.where(final_mask[..., None] == 1,\n",
    "                       cv2.addWeighted(overlay, 1 - alpha, red, alpha, 0),\n",
    "                       overlay)\n",
    "    cv2.imwrite(os.path.join(overlay_dir, mask_filename),\n",
    "                cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    print(f\"[{idx+1}/{len(frame_paths)}] Processed: {os.path.basename(path)}\")\n",
    "\n",
    "print(\"All frames processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8f0a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "GT_MASK_DIR   = \"\"  # Ground truth masks\n",
    "PRED_MASK_DIR = \"\"  # SAM2-predicted masks\n",
    "\n",
    "def compute_metrics(gt, pred):\n",
    "    gt = (gt > 127).astype(np.uint8)\n",
    "    pred = (pred > 127).astype(np.uint8)\n",
    "\n",
    "    intersection = np.logical_and(gt, pred).sum()\n",
    "    union = np.logical_or(gt, pred).sum()\n",
    "    iou = intersection / union if union > 0 else 1.0\n",
    "\n",
    "    dice = (2 * intersection) / (gt.sum() + pred.sum() + 1e-6)\n",
    "\n",
    "    mae = np.abs(gt - pred).mean()\n",
    "\n",
    "    correct = (gt == pred).sum()\n",
    "    pixel_acc = correct / gt.size\n",
    "\n",
    "    bg_correct = ((gt == 0) & (pred == 0)).sum()\n",
    "    bg_total = (gt == 0).sum()\n",
    "    bg_acc = bg_correct / bg_total if bg_total > 0 else 1.0\n",
    "\n",
    "    fg_correct = ((gt == 1) & (pred == 1)).sum()\n",
    "    fg_total = (gt == 1).sum()\n",
    "    fg_acc = fg_correct / fg_total if fg_total > 0 else 1.0\n",
    "\n",
    "    mean_acc = (bg_acc + fg_acc) / 2.0\n",
    "\n",
    "    total_pixels = gt.size\n",
    "    fw_iou = ((bg_total/total_pixels) * (bg_correct/(bg_total + (pred==1).sum() - fg_correct)) +\n",
    "              (fg_total/total_pixels) * (fg_correct/(fg_total + (pred==0).sum() - bg_correct)))\n",
    "\n",
    "    return iou, dice, mae, pixel_acc, mean_acc, fw_iou\n",
    "\n",
    "gt_paths = sorted(glob.glob(os.path.join(GT_MASK_DIR, \"*.png\")))\n",
    "pred_paths = sorted(glob.glob(os.path.join(PRED_MASK_DIR, \"*.png\")))\n",
    "\n",
    "ious, dices, maes, accs, mean_accs, fwious = [], [], [], [], [], []\n",
    "\n",
    "for gt_path, pred_path in zip(gt_paths, pred_paths):\n",
    "    gt = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "    pred = cv2.imread(pred_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if gt.shape != pred.shape:\n",
    "        pred = cv2.resize(pred, (gt.shape[1], gt.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    iou, dice, mae, acc, mean_acc, fw_iou = compute_metrics(gt, pred)\n",
    "    ious.append(iou); dices.append(dice); maes.append(mae)\n",
    "    accs.append(acc); mean_accs.append(mean_acc); fwious.append(fw_iou)\n",
    "\n",
    "print(f\"Mean IoU   : {np.mean(ious):.4f}\")\n",
    "print(f\"Mean Dice  : {np.mean(dices):.4f}\")\n",
    "print(f\"Mean MAE   : {np.mean(maes):.4f}\")\n",
    "print(f\"Pixel Acc  : {np.mean(accs):.4f}\")\n",
    "print(f\"Mean Acc   : {np.mean(mean_accs):.4f}\")\n",
    "print(f\"FWIoU      : {np.mean(fwious):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
