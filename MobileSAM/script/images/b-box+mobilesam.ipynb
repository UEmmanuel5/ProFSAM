{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "174571f2",
   "metadata": {},
   "source": [
    "## YOLOv11 + MobileSAM Pipeline (Box Prompting)\n",
    "Runs YOLO11 for fire detection and uses MobileSAM with bounding box prompts for segmentation.  \n",
    "Saves:\n",
    "- Detection visualizations with confidence scores  \n",
    "- Segmentation masks  \n",
    "- Overlays showing detected fire regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf422d1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, glob, cv2, torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from mobile_sam import sam_model_registry, SamPredictor\n",
    "\n",
    "FRAME_DIR    = \"\"   # Directory containing input frames\n",
    "YOLO_MODEL   = \"\"   # Path to YOLO model weights\n",
    "SAM_CKPT     = \"\"   # Path to mobile_sam.pt weights\n",
    "OUT_DIR      = \"\"   # Output directory for results\n",
    "IMG_SIZE     = 960\n",
    "CONF_THRESH  = 0.3\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "yolo_model = YOLO(YOLO_MODEL).to(DEVICE)\n",
    "\n",
    "sam = sam_model_registry[\"vit_t\"](checkpoint=SAM_CKPT)\n",
    "sam.to(device=DEVICE)\n",
    "sam.eval()\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "mask_dir = os.path.join(OUT_DIR, \"masks\")\n",
    "overlay_dir = os.path.join(OUT_DIR, \"overlays\")\n",
    "det_dir = os.path.join(OUT_DIR, \"detected_fires\")\n",
    "os.makedirs(mask_dir, exist_ok=True)\n",
    "os.makedirs(overlay_dir, exist_ok=True)\n",
    "os.makedirs(det_dir, exist_ok=True)\n",
    "\n",
    "frame_paths = sorted(\n",
    "    sum([glob.glob(os.path.join(FRAME_DIR, ext)) for ext in (\"*.jpg\", \"*.png\")], [])\n",
    ")\n",
    "\n",
    "for idx, path in enumerate(frame_paths):\n",
    "    img_pil = Image.open(path).convert(\"RGB\")\n",
    "    img_np  = np.array(img_pil)\n",
    "\n",
    "    results = yolo_model.predict([img_pil], imgsz=IMG_SIZE, conf=CONF_THRESH)\n",
    "    boxes_xyxy = results[0].boxes.xyxy.cpu().numpy()\n",
    "    confs = results[0].boxes.conf.cpu().numpy()\n",
    "\n",
    "    det_vis = img_np.copy()\n",
    "    for box, conf in zip(boxes_xyxy, confs):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cv2.rectangle(det_vis, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(det_vis, f\"{conf:.2f}\", (x1 - 50, y1 + 15),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    cv2.imwrite(os.path.join(det_dir, f\"{idx:05d}.png\"),\n",
    "                cv2.cvtColor(det_vis, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    predictor.set_image(img_np)\n",
    "    final_mask = np.zeros(img_np.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    for box in boxes_xyxy:\n",
    "        masks, scores, _ = predictor.predict(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            box=box[None, :], \n",
    "            multimask_output=False\n",
    "        )\n",
    "        mask = masks[0].astype(np.uint8)\n",
    "        final_mask = np.maximum(final_mask, mask)\n",
    "\n",
    "    mask_filename = f\"{idx:05d}.png\"\n",
    "    cv2.imwrite(os.path.join(mask_dir, mask_filename), final_mask * 255)\n",
    "\n",
    "    overlay = img_np.copy()\n",
    "    red = np.zeros_like(img_np); red[:] = (255, 0, 0)\n",
    "    overlay = np.where(final_mask[..., None] == 1,\n",
    "                       cv2.addWeighted(overlay, 0.6, red, 0.4, 0),\n",
    "                       overlay)\n",
    "    cv2.imwrite(os.path.join(overlay_dir, mask_filename),\n",
    "                cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    print(f\"[{idx+1}/{len(frame_paths)}] Processed: {os.path.basename(path)}\")\n",
    "\n",
    "print(\"All frames processed with MobileSAM + YOLO boxes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1941de2d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "GT_MASK_DIR   = \"\"  # Ground truth masks\n",
    "PRED_MASK_DIR = \"\"  # SAM2-predicted masks\n",
    "\n",
    "def compute_metrics(gt, pred):\n",
    "    gt = (gt > 127).astype(np.uint8)\n",
    "    pred = (pred > 127).astype(np.uint8)\n",
    "\n",
    "    intersection = np.logical_and(gt, pred).sum()\n",
    "    union = np.logical_or(gt, pred).sum()\n",
    "    iou = intersection / union if union > 0 else 1.0\n",
    "\n",
    "    dice = (2 * intersection) / (gt.sum() + pred.sum() + 1e-6)\n",
    "\n",
    "    mae = np.abs(gt - pred).mean()\n",
    "\n",
    "    correct = (gt == pred).sum()\n",
    "    pixel_acc = correct / gt.size\n",
    "\n",
    "    bg_correct = ((gt == 0) & (pred == 0)).sum()\n",
    "    bg_total = (gt == 0).sum()\n",
    "    bg_acc = bg_correct / bg_total if bg_total > 0 else 1.0\n",
    "\n",
    "    fg_correct = ((gt == 1) & (pred == 1)).sum()\n",
    "    fg_total = (gt == 1).sum()\n",
    "    fg_acc = fg_correct / fg_total if fg_total > 0 else 1.0\n",
    "\n",
    "    mean_acc = (bg_acc + fg_acc) / 2.0\n",
    "\n",
    "    total_pixels = gt.size\n",
    "    fw_iou = ((bg_total/total_pixels) * (bg_correct/(bg_total + (pred==1).sum() - fg_correct)) +\n",
    "              (fg_total/total_pixels) * (fg_correct/(fg_total + (pred==0).sum() - bg_correct)))\n",
    "\n",
    "    return iou, dice, mae, pixel_acc, mean_acc, fw_iou\n",
    "\n",
    "gt_paths = sorted(glob.glob(os.path.join(GT_MASK_DIR, \"*.png\")))\n",
    "pred_paths = sorted(glob.glob(os.path.join(PRED_MASK_DIR, \"*.png\")))\n",
    "\n",
    "ious, dices, maes, accs, mean_accs, fwious = [], [], [], [], [], []\n",
    "\n",
    "for gt_path, pred_path in zip(gt_paths, pred_paths):\n",
    "    gt = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "    pred = cv2.imread(pred_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if gt.shape != pred.shape:\n",
    "        pred = cv2.resize(pred, (gt.shape[1], gt.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    iou, dice, mae, acc, mean_acc, fw_iou = compute_metrics(gt, pred)\n",
    "    ious.append(iou); dices.append(dice); maes.append(mae)\n",
    "    accs.append(acc); mean_accs.append(mean_acc); fwious.append(fw_iou)\n",
    "\n",
    "print(f\"Mean IoU   : {np.mean(ious):.4f}\")\n",
    "print(f\"Mean Dice  : {np.mean(dices):.4f}\")\n",
    "print(f\"Mean MAE   : {np.mean(maes):.4f}\")\n",
    "print(f\"Pixel Acc  : {np.mean(accs):.4f}\")\n",
    "print(f\"Mean Acc   : {np.mean(mean_accs):.4f}\")\n",
    "print(f\"FWIoU      : {np.mean(fwious):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
