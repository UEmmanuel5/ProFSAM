{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58d1e08",
   "metadata": {},
   "source": [
    "## YOLOv11 + TinySAM Video Segmentation (Box Prompting)\n",
    "Processes video frames with YOLOv11 for detection and TinySAM for segmentation using bounding box prompts.  \n",
    "Saves:\n",
    "- detection frames  \n",
    "- segmentation masks  \n",
    "- overlays  \n",
    "Outputs final annotated video and reports model size, FPS, inference time, and GPU memory usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d36850",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from tinysam import sam_model_registry, SamPredictor\n",
    "\n",
    "\n",
    "VIDEO_PATH   = \"\"   # Directory containing input video\n",
    "YOLO_MODEL   = \"\"   # Path to YOLO model weights\n",
    "TINY_CKPT    = \"\"   # Path to YOLO model tinysam_42.3.pth weights\n",
    "OUT_DIR      = \"\"   # Output directory for results\n",
    "IMG_SIZE     = 960\n",
    "CONF_THRESH  = 0.3\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "yolo_model = YOLO(YOLO_MODEL).to(DEVICE)\n",
    "sam = sam_model_registry[\"vit_t\"](checkpoint=TINY_CKPT)\n",
    "sam.to(device=DEVICE)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "mask_dir = os.path.join(OUT_DIR, \"masks\")\n",
    "overlay_dir = os.path.join(OUT_DIR, \"overlays\")\n",
    "det_dir = os.path.join(OUT_DIR, \"detected_fires\")\n",
    "os.makedirs(mask_dir, exist_ok=True)\n",
    "os.makedirs(overlay_dir, exist_ok=True)\n",
    "os.makedirs(det_dir, exist_ok=True)\n",
    "\n",
    "param_count_yolo = sum(p.numel() for p in yolo_model.model.parameters())\n",
    "param_count_tinysam = sum(p.numel() for p in sam.parameters())\n",
    "model_size_mb = (param_count_yolo + param_count_tinysam) * 4 / (1024**2)\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "print(f\"YOLO Parameters: {param_count_yolo:,}\")\n",
    "print(f\"TinySAM Parameters: {param_count_tinysam:,}\")\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out_video_path = os.path.join(OUT_DIR, \"final_output.avi\")\n",
    "out_writer = cv2.VideoWriter(out_video_path, fourcc, fps, (frame_w, frame_h))\n",
    "\n",
    "frame_count = 0\n",
    "total_time = 0.0\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(img_rgb)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    results = yolo_model.predict([img_pil], imgsz=IMG_SIZE, conf=CONF_THRESH, verbose=False)\n",
    "    boxes_xyxy = results[0].boxes.xyxy.cpu().numpy()\n",
    "    confs = results[0].boxes.conf.cpu().numpy()\n",
    "\n",
    "    det_vis = img_rgb.copy()\n",
    "    for box, conf in zip(boxes_xyxy, confs):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cv2.rectangle(det_vis, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(det_vis, f\"{conf:.2f}\", (x1 - 50, y1 + 15),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    cv2.imwrite(os.path.join(det_dir, f\"{frame_count:05d}.png\"),\n",
    "                cv2.cvtColor(det_vis, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    predictor.set_image(img_rgb)\n",
    "    final_mask = np.zeros(img_rgb.shape[:2], dtype=np.uint8)\n",
    "    for box in boxes_xyxy:\n",
    "        masks, scores, logits = predictor.predict(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            box=box[None, :]\n",
    "        )\n",
    "        mask = masks[0].astype(np.uint8)\n",
    "        final_mask = np.maximum(final_mask, mask)\n",
    "\n",
    "    cv2.imwrite(os.path.join(mask_dir, f\"{frame_count:05d}.png\"), final_mask * 255)\n",
    "\n",
    "    overlay = img_rgb.copy()\n",
    "    red = np.zeros_like(img_rgb); red[:] = (255, 0, 0)\n",
    "    overlay = np.where(final_mask[..., None] == 1,\n",
    "                       cv2.addWeighted(overlay, 0.6, red, 0.4, 0),\n",
    "                       overlay)\n",
    "    overlay_bgr = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(os.path.join(overlay_dir, f\"{frame_count:05d}.png\"), overlay_bgr)\n",
    "\n",
    "    out_writer.write(overlay_bgr)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    total_time += elapsed\n",
    "    print(f\"[{frame_count}] Frame processed in {elapsed*1000:.2f} ms\")\n",
    "\n",
    "cap.release()\n",
    "out_writer.release()\n",
    "\n",
    "avg_time_ms = (total_time / frame_count) * 1000\n",
    "fps_actual = frame_count / total_time\n",
    "peak_mem_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "\n",
    "print(f\"\\n--- Computational Efficiency ---\")\n",
    "print(f\"Average Inference Time: {avg_time_ms:.2f} ms/frame\")\n",
    "print(f\"FPS: {fps_actual:.2f}\")\n",
    "print(f\"Peak GPU Memory: {peak_mem_mb:.2f} MB\")\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "print(f\"Output video saved to: {out_video_path}\")\n",
    "print(f\"Detection images, masks, and overlays saved to: {OUT_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
